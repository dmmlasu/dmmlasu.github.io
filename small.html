<html>
<h1 align="center">III: SMALL: Graph Contrastive Learning for Few-Shot Node Classification</h1>
<body>

<h2>Description</h2>
<p>The SMALL project is a cutting-edge research initiative focused on enhancing Few-Shot Node Classification (FSNC) using Graph Contrastive Learning (GCL). This project aims to bridge the gap in graph learning where labeled data is scarce, providing robust methodologies that ensure high accuracy in node classification across fully supervised, weakly supervised, and unsupervised settings. By exploring the intersection of contrastive learning and graph structures, SMALL seeks to develop innovative strategies for effective few-shot learning on graphs.</p>

<p>Specifically, the SMALL project targets the development of methodologies that are not only accurate but also interpretable and resilient to adversarial attacks. With a comprehensive approach that includes dataset collection, benchmarking, and tool development, SMALL is poised to make significant contributions to both theoretical research and practical applications in graph-based learning.</p>

<h2>Objectives</h2>
<ul>
  <li>Investigate the effectiveness of GCL methods for FSNC tasks across various supervision settings.</li>
  <li>Benchmark state-of-the-art methods and develop a unified evaluation pipeline for standardized testing.</li>
  <li>Explore methodologies for enhancing model interpretability, robustness against adversarial attacks, and validation of mispredictions.</li>
  <li>Curate and collect datasets specific to FSNC to establish a reliable benchmark for future research.</li>
  <li>Release tools, datasets, and software for community engagement and further exploration.</li>
</ul>

<h2>Research Areas</h2>
<ul>
  <li><strong>Benchmarking and Analysis:</strong> Compare state-of-the-art methods for FSNC across a variety of datasets and conditions, including supervised, weakly supervised, and unsupervised scenarios.</li>
  <li><strong>Exploratory Methodologies:</strong> Investigate new frameworks, such as Transductive Linear Probing (TLP) and Virtual Node Tuning (VNT), to improve classification performance in low-data settings.</li>
  <li><strong>Dataset Collection and Curation:</strong> Identify, collect, and curate datasets for FSNC tasks to expand current benchmarks and enhance model training.</li>
  <li><strong>Graph Contrastive Learning (GCL) Methods:</strong> Develop GCL strategies that foster effective learning in few-shot node classification tasks while ensuring model robustness.</li>
  <li><strong>Interpretability and Robustness:</strong> Design interpretability frameworks to understand model decisions and enhance resilience to adversarial attacks.</li>
  <li><strong>Reliable Learning on Graphs:</strong> Validate mispredictions by integrating ontology-aware knowledge graphs to improve the accuracy and reliability of node classification models.</li>
</ul>

<h2>Tasks</h2>
<ul>
  <li>Conduct comprehensive benchmarking of GCL and meta-learning methods for FSNC.</li>
  <li>Explore interpretability techniques to enhance model understanding and decision-making transparency.</li>
  <li>Develop robust methodologies to detect and prevent adversarial attacks in graph-based models.</li>
  <li>Expand and curate FSNC-specific datasets for more accurate and generalized model evaluation.</li>
  <li>Release publicly accessible datasets, code, and tools to promote open research and collaboration within the academic and industrial communities.</li>
</ul>

<h2>Major Activities and Accomplishments</h2>
<p>The SMALL project has initiated several key activities aimed at advancing the field of FSNC:</p>
<ul>
  <li><strong>Benchmarking & Analysis:</strong> Established a comparative analysis of existing methods on widely-used datasets to provide a baseline for future research.</li>
  <li><strong>Dataset Enrichment:</strong> Collected and curated additional datasets to strengthen the benchmark data for FSNC.</li>
  <li><strong>Repository Creation:</strong> Developed a repository containing GCL and meta-learning methods explored in the project to support ongoing research efforts.</li>
  <li><strong>Evaluation Pipeline:</strong> Built a unified evaluation pipeline for consistent and standardized comparisons across methods.</li>
  <li><strong>Website Development:</strong> Launched a project website to share results, datasets, and publications with the broader community.</li>
</ul>

<h2>Publications</h2>
<ul>
  <li>Tan, Z., Wang, S., Ding, K., Li, J., & Liu, H. (2022). Transductive Linear Probing: A Novel Framework for Few-Shot Node Classification. In Learning on Graphs Conference (pp. 4-1). PMLR.</li>
  <li>Tan, Z., Ding, K., Guo, R., & Liu, H. (2022). Supervised Graph Contrastive Learning for Few-Shot Node Classification. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 394-411). Springer.</li>
  <li>Tan, Z., Guo, R., Ding, K., Liu, H. (2023). Virtual Node Tuning for Few-shot Node Classification. In Proceedings of the 29th ACM SIGKDD Conference (pp. 2177–2188).</li>
  <li>Wang, S., Tan, Z., Liu, H., & Li, J. (2023). Contrastive Meta-Learning for Few-shot Node Classification. In Proceedings of the 29th ACM SIGKDD Conference (pp. 2386-2397).</li>
  <li>Mathavan, H., Tan, İ. Z., Mudiam, N., & Liu, H. (2023). Inductive Linear Probing for Few-Shot Node Classification. In SBP-BRiMS 2023 (p. 274). Springer Nature.</li>
  <li>Tan, Z., Cheng, L., Wang, S., Yuan, B., Li, J., & Liu, H. (2024). Interpreting Pretrained Language Models via Concept Bottlenecks. In PAKDD 2024. Springer.</li>
  <li>Tan, Z., Chen, T., Zhang, Z., & Liu, H. (2024). Sparsity-Guided Holistic Explanation for LLMs with Interpretable Inference-Time Intervention. In AAAI 2024.</li>
  <li>Tan, Z., Zhao, C., Moraffah, R., & Liu, H. (2024). The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative. In ReGenAI@CVPR 2024.</li>
  <li>Tan, Z., Li, D., Wang, S., Beigi, A., et al. (2024). Large Language Models for Data Annotation: A Survey. In EMNLP 2024.</li>
  <li>Zhao, C., Agrawal, G., Kumarage, T., et al. (2024). Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education. Submitted to AAAI 2025.</li>
</ul>

<h2>Related Links</h2>
<ul>
  <li><a href="https://dmmlasu.github.io/small.html">SMALL Project Website</a></li>
</ul>

<h2>Resources</h2>
<ul>
  <li><a href="http://snap.stanford.edu/data/index.html#signnets">Stanford Large Network Dataset Collection (SNAP)</a> - Signed Social Networks</li>
</ul>

<h2>Project Members</h2>
<ul>
  <li>Principal Investigator: Huan Liu</li>
  <li>Graduate Research Assistant: Zhen Tan & Chengshuai Zhao</li>
</ul>

<h2>Acknowledgments</h2>
<p>This project is supported by the National Science Foundation (NSF) under Grant #2311716. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF.</p>

<hr width="100%">
<p><b>Last Updated: Oct 5th, 2024</b></p>

</body>
</html>
